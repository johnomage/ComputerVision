{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18932b3b",
   "metadata": {},
   "source": [
    "CONVOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294123a5",
   "metadata": {},
   "source": [
    "# output image = image ⨂ FUNCTIONκ   (k = kernel size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "16929b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv, numpy as np\n",
    "image = cv.imread(\"C:/opencv/images/input.jpg\")\n",
    "elephant = cv.imread(\"C:/opencv/images/elephant.jpg\")\n",
    "sunflower = cv.imread(\"C:/opencv/images/sunflowers.jpg\")\n",
    "species = cv.imread(\"C:/opencv/images/Origin_of_Species.jpg\", 0)\n",
    "gradient = cv.imread(\"C:/opencv/images/gradient.jpg\", 0) # 0 converts to greyscale\n",
    "opencv = cv.imread(\"C:/opencv/images/opencv.png\", 0)\n",
    "skan = cv.imread(\"C:/opencv/images/scan.jpg\")\n",
    "ex2 = cv.imread(\"C:/opencv/images/ex2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4cbf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv.imshow(\"Original Image\", image)\n",
    "cv.waitKey()\n",
    "\n",
    "#Create 3x3 kernel\n",
    "kernel33 = np.ones((3,3), \"float32\") / 9\n",
    "\n",
    "#use cv.filter2D to convolve the kernel with image\n",
    "blurred33 = cv.filter2D(image, -1, kernel33)\n",
    "cv.imshow(\"3x3 Kernel Blur\", blurred33)\n",
    "cv.waitKey()\n",
    "\n",
    "#create 7x7 kernel\n",
    "kernel77 = np.ones((7,7), \"float32\")/49\n",
    "blurred77 = cv.filter2D(image, -1, kernel77)\n",
    "cv.imshow(\"7x7 Kernel Blur\", blurred77)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b099145",
   "metadata": {},
   "source": [
    "Other openCV blurring methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb3318ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Blur\n",
    "blur = cv.blur(image, (3,3))\n",
    "cv.imshow(\"BLUR\", blur)\n",
    "cv.waitKey()\n",
    "\n",
    "#gaussian Blur\n",
    "gaussian = cv.GaussianBlur(image, (7,7), 0)\n",
    "cv.imshow(\"Gaussian Blur\", gaussian)\n",
    "cv.waitKey()\n",
    "\n",
    "#Median Blur\n",
    "median = cv.medianBlur(image, 5)\n",
    "cv.imshow(\"Median Blur\", median)\n",
    "cv.waitKey()\n",
    "\n",
    "#Bilateral Blur\n",
    "bilateral = cv.bilateralFilter(image, 9, 75, 75)\n",
    "cv.imshow(\"Bilateral Blur\", blur)\n",
    "cv.waitKey()\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af476f2",
   "metadata": {},
   "source": [
    "Image De-noising - Non-Locals Means Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6df49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters, after None: filter strength \"h\" (5-10 is a good range), next is hForColorComponents (same as h)\n",
    "\n",
    "cv.imshow(\"Original\", sunflower)\n",
    "cv.waitKey(0)\n",
    "\n",
    "\n",
    "dst = cv.fastNlMeansDenoisingColored(sunflower, None, 6,6,7,21)\n",
    "cv.imshow(\"Fast Means Denoising\", dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f56ea7",
   "metadata": {},
   "source": [
    "SHARPENING\n",
    "\n",
    "opposite of blurring.strengthens or emphasizes edges in an image.\n",
    "\n",
    "kernel matrix must sum to 1 (means multiply by a fator that retains original brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82fc5f4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-ea88ec9179fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m sharpening_matrix = np.array([[-1,-1,-1],\n\u001b[0;32m      5\u001b[0m                             \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - mat is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::cuda::GpuMat> for argument 'mat'\n>  - Expected Ptr<cv::UMat> for argument 'mat'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv.imshow(\"Original\", input)\n",
    "cv.waitKey(0)\n",
    "\n",
    "sharpening_matrix = np.array([[-1,-1,-1],\n",
    "                            [-1,9,-1],\n",
    "                            [-1,-1,-1]])\n",
    "#apply to filter\n",
    "sharpened = cv.filter2D(input, -1, sharpening_matrix)\n",
    "cv.imshow(\"Sharpened Image\", sharpened)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c03b5c",
   "metadata": {},
   "source": [
    "THRESHOLDING, BINARISATION, ADAPTIVE IMAGING\n",
    "\n",
    "Thresholding = coverting am image to its binary form.\n",
    "\n",
    "        cv2.threshold(image, thresholdValue, maxValue, thresholdType)\n",
    "        \n",
    "        thresholValue: 0-126 = black, 127-255 = white\n",
    "        \n",
    "        thresholdTypes:\n",
    "        \n",
    "            1. cv2.THRESH_BINARY - most common\n",
    "            2. cv2.THRESH_BINARY_INV - most common too\n",
    "            3. cv2.THRESH_TRUNC\n",
    "            4. cv2.THRESH_TOZERO\n",
    "            5. cv2.THRESH_TOZERO_INV\n",
    "        convert image to greyscale before threesholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e015e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.0\n"
     ]
    }
   ],
   "source": [
    "# grey_grad = cv.imread(\"gradient\", 0)\n",
    "cv.imshow(\"Original\", gradient)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "# Binary threshold:\n",
    "ret, bin_threshold = cv.threshold(gradient, 127, 255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"Binary Threshold\", bin_threshold)\n",
    "cv.waitKey()\n",
    "\n",
    "# Inv Binary threshold:\n",
    "ret, invbin_threshold = cv.threshold(gradient, 127, 255, cv.THRESH_BINARY_INV)\n",
    "cv.imshow(\"Inv Binary Threshold\", invbin_threshold)\n",
    "cv.waitKey()\n",
    "\n",
    "# Trunc threshold:\n",
    "ret, trunc_threshold = cv.threshold(gradient, 127, 255, cv.THRESH_TRUNC)\n",
    "cv.imshow(\" Threshold\", trunc_threshold)\n",
    "cv.waitKey()\n",
    "\n",
    "# Tozero threshold:\n",
    "ret, tozero_threshold = cv.threshold(gradient, 127, 255, cv.THRESH_TOZERO)\n",
    "cv.imshow(\"To zero Threshold\", tozero_threshold)\n",
    "cv.waitKey()\n",
    "\n",
    "# Inv Tozero threshold:\n",
    "ret, invtozero_threshold = cv.threshold(gradient, 127, 255, cv.THRESH_TOZERO_INV)\n",
    "cv.imshow(\"INVTo zero Threshold\", invtozero_threshold)\n",
    "cv.waitKey()\n",
    "print(ret)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1662d930",
   "metadata": {},
   "source": [
    "ADAPTIVE THRESHOLDING = better way if thresholding. \n",
    "\n",
    "Blur image first to remove noise. Very important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afe816c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species = species.astype(np.uint8)\n",
    "cv.imshow(\"Original\", species)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Binary threshold:\n",
    "ret, bin_threshold = cv.threshold(species, 127, 255, cv.THRESH_BINARY)\n",
    "cv.imshow(\"Binary Threshold\", bin_threshold)\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Blur image first\n",
    "gauss_blur = cv.GaussianBlur(species, (3,3), 0)\n",
    "thresh = cv.adaptiveThreshold(gauss_blur, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 3, 5)\n",
    "cv.imshow(\"Adaptive threshold mean\", thresh)\n",
    "cv.waitKey(0)\n",
    "\n",
    "x, otsu = cv.threshold(species, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "cv.imshow(\"OTSU threshold\", otsu)\n",
    "cv.waitKey(0)\n",
    "# print(x)\n",
    "\n",
    "gauss_species = cv.GaussianBlur(species, (5,5), 0)\n",
    "y, gauss_otsu = cv.threshold(gauss_species, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "cv.imshow(\"Gauss OTSU threshold\", gauss_otsu)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f2918",
   "metadata": {},
   "source": [
    "DILATION AND EROSION\n",
    "\n",
    "dilation = adds pixels to the boundaris of objects in an image\n",
    "\n",
    "erosion = removes pixels to the boundaris of objects in an image\n",
    "\n",
    "opening = erosion followed by dilation (good for noise removal)\n",
    "\n",
    "closing = dilation followed by erosion (good for noise removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08a3bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, inv_opencv = cv.threshold(opencv, 127, 255, cv.THRESH_BINARY_INV)\n",
    "cv.imshow(\"Original\", inv_opencv)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "# define kernel size\n",
    "kernel = np.ones((4,1), np.uint8)\n",
    "\n",
    "# erode\n",
    "erosion = cv.erode(inv_opencv, kernel, 1)\n",
    "cv.imshow(\"Erosion\", erosion)\n",
    "cv.waitKey()\n",
    "\n",
    "# dilate\n",
    "dilation = cv.dilate(inv_opencv, kernel, 1)\n",
    "cv.imshow(\"Dilation\", dilation)\n",
    "cv.waitKey()\n",
    "\n",
    "# opening\n",
    "opening = cv.morphologyEx(inv_opencv, cv.MORPH_ELLIPSE, kernel)\n",
    "cv.imshow(\"opening\", opening)\n",
    "cv.waitKey()\n",
    "\n",
    "# closing\n",
    "closing = cv.morphologyEx(inv_opencv, cv.MORPH_CLOSE, kernel)\n",
    "cv.imshow(\"Closing\", closing)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec7526",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c81d04f7",
   "metadata": {},
   "source": [
    "<b>EDGE DETECTION AND IMAGE GRADIENT</b>\n",
    "\n",
    "edge = sudden changes (discontinuitites) in an image and they can encide as mush info as pixels.\n",
    "\n",
    "<u>Three main types of edge detection algorithms</u>\n",
    "\n",
    "    1. Sobel = emphasizes vertical or horizontal edges\n",
    "    2. Laplacean = gets all orientations\n",
    "    3. Canny = optimal due to low error rate, well defined edges and accurate detection\n",
    "\n",
    "Canny detection Algorithm (Developed by John F. Canny, 1986)\n",
    " \n",
    "    1. Applies Gaussian blurring\n",
    "    2. Finds intensity gradient of the image\n",
    "    3. Applies non-maximum suppression (removes pixels that are not edges)\n",
    "    4. Hysterisis = Applies thresholds (if pixel is within the upper and lower thresholds, it is considered an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b2d79ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Original\", image)\n",
    "cv.waitKey()\n",
    "\n",
    "height, width, depth = image.shape\n",
    "\n",
    "# Extract Sobel edges\n",
    "xSobel = cv.Sobel(image, cv.CV_64F, 0, 1, ksize=5)\n",
    "cv.imshow(\"Horintal Sobel\", xSobel)\n",
    "cv.waitKey()\n",
    "\n",
    "ySobel = cv.Sobel(image, cv.CV_64F, 1, 0, ksize=5)\n",
    "cv.imshow(\"Vertical Sobel\", ySobel)\n",
    "cv.waitKey()\n",
    "\n",
    "sobel_or = cv.bitwise_or(xSobel, ySobel)\n",
    "cv.imshow(\"OR Sobel\", sobel_or)\n",
    "cv.waitKey()\n",
    "\n",
    "# Laplacean\n",
    "laplacean = cv.Laplacian(image, cv.CV_64F)\n",
    "cv.imshow(\"Laplacean\", laplacean)\n",
    "cv.waitKey()\n",
    "\n",
    "# Canny\n",
    "# uses two values: threshold1 and threshold2. Gradient higher than t2 is considered to be an edge, lower than\n",
    "# t1 is considered not an edge, between t1 and t2 would depend on how intensities are \"connected\".\n",
    "canny = cv.Canny(image, 50, 180)\n",
    "cv.imshow(\"Canny\", canny)\n",
    "cv.waitKey()\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cb245",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0904a3",
   "metadata": {},
   "source": [
    "<u>Obtaing PErspective of Non-Affine Transforms</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe7edaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv.imshow(\"Original\", skan)\n",
    "cv.waitKey()\n",
    "\n",
    "#get coordinates of the 4 corners of the image\n",
    "original_coord = np.float32([[320,15], [700,215], [85,610], [530,780]])\n",
    "\n",
    "# desired coordinates. A4 paper ratio used = 1:1.41\n",
    "transformed_coord = np.float32([[0,0], [420,0], [0,594], [420,594]])\n",
    "\n",
    "# perspectve transformation matrix, M\n",
    "M = cv.getPerspectiveTransform(original_coord, transformed_coord)\n",
    "\n",
    "warped = cv.warpPerspective(skan, M, (420,594))\n",
    "\n",
    "cv.imshow(\"warpPerspective\", warped)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19c62f",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b1f7f",
   "metadata": {},
   "source": [
    "With affine transform, you only need 3 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3cb0cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Original\", ex2)\n",
    "cv.waitKey()\n",
    "\n",
    "col, row, channel = ex2.shape\n",
    "\n",
    "#get coordinates of the 4 corners of the image\n",
    "original_coord = np.float32([[320,15], [700,215], [85,610]])\n",
    "\n",
    "# desired coordinates. A4 paper ratio used = 1:1.41\n",
    "transformed_coord = np.float32([[0,0], [420,0], [0,594]])\n",
    "\n",
    "# perspectve transformation matrix, M\n",
    "M = cv.getAffineTransform(original_coord, transformed_coord)\n",
    "\n",
    "affine = cv.warpAffine(ex2, M, (420,594))\n",
    "\n",
    "cv.imshow(\"warpAffine\", affine)\n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b088e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
